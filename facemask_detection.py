# -*- coding: utf-8 -*-
"""facemask detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_3t59eidaKLtPyx8UEk6e8JvpcFDxEsX
"""


import os

# Set a base directory where data will be stored
# Change this to any valid path (e.g., "D:/datasets/imagedata")
base_dir = os.path.join(os.getcwd(), 'Facemask_dataset')  # Creates directory in current working directory

# Define training and validation directories
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

# Create the main directories
os.makedirs(train_dir, exist_ok=True)
os.makedirs(validation_dir, exist_ok=True)

# Create subdirectories for 'mask' and 'no_mask' inside both training and validation directories
for sub_dir in ['mask', 'no_mask']:
    os.makedirs(os.path.join(train_dir, sub_dir), exist_ok=True)
    os.makedirs(os.path.join(validation_dir, sub_dir), exist_ok=True)

# Print confirmation message with correct paths
print(f"Training and validation directories created successfully at:\n{train_dir}\n{validation_dir}")



import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the CNN model
def create_cnn_model():
    model = models.Sequential()

    # Convolutional Layer 1
    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
    model.add(layers.MaxPooling2D((2, 2)))

    # Convolutional Layer 2
    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))

    # Convolutional Layer 3
    model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))

    # Flatten the results and add a Dense layer
    model.add(layers.Flatten())
    model.add(layers.Dense(128, activation='relu'))

    # Output Layer: A single neuron with sigmoid activation for binary classification
    model.add(layers.Dense(1, activation='sigmoid'))

    # Compile the model
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    return model

# Initialize the model
model = create_cnn_model()

# Display the model summary
model.summary()

import zipfile
import os

# Define the extraction directory (modify as needed)
extract_path = os.path.join(os.getcwd(), 'Facemask_Dataset')

# Extract the ZIP file
with zipfile.ZipFile('Facemask Detection.zip', 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(f"Files extracted successfully to: {extract_path}")

import os

# Define base directory in the current working directory
base_dir = os.path.join(os.getcwd(), 'Facemask Detection')

# Define training & validation directories inside 'dataset'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

# Create directories if they do not exist
os.makedirs(train_dir, exist_ok=True)
os.makedirs(validation_dir, exist_ok=True)

print(f"Directories created at:\n{train_dir}\n{validation_dir}")

import os
import shutil
from sklearn.model_selection import train_test_split

# Define the dataset directory (Change this path accordingly)
dataset_dir = r"C:\Users\Lenova\Facemask Detection\data"
mask_dir = os.path.join(dataset_dir, "with_mask")  # Folder containing images with masks
no_mask_dir = os.path.join(dataset_dir, "without_mask")  # Folder containing images without masks

# Define output directories
train_dir = os.path.join(dataset_dir, "train")
validation_dir = os.path.join(dataset_dir, "validation")

# Create train/validation directories if they don't exist
for category in ["mask", "no_mask"]:
    os.makedirs(os.path.join(train_dir, category), exist_ok=True)
    os.makedirs(os.path.join(validation_dir, category), exist_ok=True)

# Function to split and move images
def split_data(source_dir, train_dest, val_dest, split_ratio=0.2):
    # Get list of all image files
    images = [f for f in os.listdir(source_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    # Split into training and validation sets
    train_files, val_files = train_test_split(images, test_size=split_ratio, random_state=42)

    # Move training images
    for file in train_files:
        shutil.move(os.path.join(source_dir, file), os.path.join(train_dest, file))

    # Move validation images
    for file in val_files:
        shutil.move(os.path.join(source_dir, file), os.path.join(val_dest, file))

# Split and move files for both categories
split_data(mask_dir, os.path.join(train_dir, "mask"), os.path.join(validation_dir, "mask"))
split_data(no_mask_dir, os.path.join(train_dir, "no_mask"), os.path.join(validation_dir, "no_mask"))

print("✅ Data split successfully!")

import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define base directory (modify as needed)
base_dir = os.path.join(os.getcwd(), 'Facemask Detection\data')

# Define training and validation directories inside 'dataset'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

# Ensure directories exist
if not os.path.exists(train_dir) or not os.path.exists(validation_dir):
    raise FileNotFoundError(f"Dataset directories not found! Check paths:\n{train_dir}\n{validation_dir}")

# Print confirmation
print(f"Using dataset from:\nTrain: {train_dir}\nValidation: {validation_dir}")

# Set up ImageDataGenerators for data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,  # Normalize pixel values (0 to 1)
    rotation_range=20,  # Random rotation
    width_shift_range=0.2,  # Horizontal shift
    height_shift_range=0.2,  # Vertical shift
    shear_range=0.2,  # Shear transformation
    zoom_range=0.2,  # Zoom in/out
    horizontal_flip=True,  # Flip images horizontally
    fill_mode='nearest'  # Fill missing pixels
)

# Only rescale for validation (no augmentation)
validation_datagen = ImageDataGenerator(rescale=1./255)

# Create generators for training and validation data
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),  # Resize images
    batch_size=32,
    class_mode='binary'  # Binary classification (mask vs no mask)
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# Set the correct dataset paths (Modify as per your folder structure)
train_dir = r"C:\Users\Lenova\Facemask Detection\data\train"
validation_dir = r"C:\Users\Lenova\Facemask Detection\data\validation"

# Check if the directories exist
if os.path.exists(train_dir) and os.path.exists(validation_dir):
    print("Train directory contents:", os.listdir(train_dir))
    print("Validation directory contents:", os.listdir(validation_dir))
else:
    print("❌ ERROR: One or both directories do not exist!")

# Check file extensions in the train directory

# Define the correct train directory path (Update as needed)
train_dir = r"C:\Users\Lenova\Facemask Detection\data\train"

# Check if the directory exists
if not os.path.exists(train_dir):
    print(f"❌ ERROR: Train directory not found at {train_dir}")
else:
    # List files in the train directory
    train_files = os.listdir(train_dir)

    # Print filename and its extension
    for file in train_files:
        print(file, os.path.splitext(file)[-1])

# Define the base directory (modify this to your actual dataset path)
base_dir = r'C:\Users\Lenova\Facemask Detection\data\train'

# Define the paths for the 'mask' and 'no_mask' folders
mask_dir = os.path.join(base_dir, 'mask')
no_mask_dir = os.path.join(base_dir, 'no_mask')

# Check if the directories exist before listing their contents
if os.path.exists(mask_dir):
    print("Mask folder contents:", os.listdir(mask_dir))
else:
    print(f"Mask directory not found at {mask_dir}")

if os.path.exists(no_mask_dir):
    print("No_mask folder contents:", os.listdir(no_mask_dir))
else:
    print(f"No_mask directory not found at {no_mask_dir}")

import os

# Define dataset paths (Modify if needed)
train_mask_dir = r"C:\Users\Lenova\Facemask Detection\data\train\mask"
train_no_mask_dir = r"C:\Users\Lenova\Facemask Detection\data\train\no_mask"
validation_mask_dir = r"C:\Users\Lenova\Facemask Detecction\data\validation\mask"
validation_no_mask_dir = r"C:\Users\Lenova\Facemask Detection\data\validation\no_mask"

# Function to check and print folder contents
def check_folder_contents(folder_path, folder_name):
    if os.path.exists(folder_path):
        print(f"{folder_name} contents:", os.listdir(folder_path))
    else:
        print(f"❌ ERROR: {folder_name} folder not found at {folder_path}")

# Check contents of each folder
check_folder_contents(train_mask_dir, "Train mask folder")
check_folder_contents(train_no_mask_dir, "Train no_mask folder")
check_folder_contents(validation_mask_dir, "Validation mask folder")
check_folder_contents(validation_no_mask_dir, "Validation no_mask folder")

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=10,  # Adjust number of epochs as needed
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size
)

# Save the model after training
model.save('mask_detection_cnn_model.h5')

# Evaluate the model
loss, accuracy = model.evaluate(validation_generator)
print(f"Validation Accuracy: {accuracy*100:.2f}%")

pip install opencv-python

pip install opencv-contrib-python

import cv2
import numpy as np
from tensorflow.keras.preprocessing.image import img_to_array
import tensorflow as tf

# Load the trained CNN model
model = tf.keras.models.load_model('mask_detection_cnn_model.h5')

# Initialize OpenCV face detector
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Start the webcam
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Convert to grayscale for face detection
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect faces
    faces = face_cascade.detectMultiScale(gray, 1.1, 4)

    for (x, y, w, h) in faces:
        # Extract the region of interest (the face)
        face = frame[y:y+h, x:x+w]

        # Resize and preprocess the face image for model prediction
        face_resized = cv2.resize(face, (224, 224))
        face_resized = face_resized.astype('float32') / 255.0  # Normalize
        face_resized = np.expand_dims(face_resized, axis=0)  # Add batch dimension

        # Make a prediction
        prediction = model.predict(face_resized)

        # Display the label and bounding box (Green for Mask, Red for No Mask)
        label = "Mask" if prediction[0] > 0.5 else "No Mask"
        color = (0, 255, 0) if label == "Mask" else (0, 0, 255)

        # Draw rectangle and label on the frame
        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

    # Display the frame with bounding boxes
    cv2.imshow('Face Mask Detection', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close all windows
cap.release()
cv2.destroyAllWindows()

pip install flask

